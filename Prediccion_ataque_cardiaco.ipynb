{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MULTIPLES CLASIFICADORES PARA UNA BASE DE DATOS PARA PREDECIR UN ATAQUE CARDIACO**\\\n",
        "Victor Manuel Buitrago Diaz\\\n",
        "20171005049\\\n",
        "Topicos avanzados en automatica"
      ],
      "metadata": {
        "id": "fpqiuPTuS8dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conjunto de datos de análisis y predicción de ataques cardíacos\n",
        "* age : Edad del paciente\n",
        "* Sex : Sexo del paciente\n",
        "* exang: angina inducida por el ejercicio (1 = sí; 0 = no)\n",
        "* ca: número de buques principales (0-3)\n",
        "* cp : Tipo de dolor torácico tipo de dolor torácico\\\n",
        "  Valor 1: angina típica\\\n",
        "  Valor 2: angina atípica\\\n",
        "  Valor 3: dolor no anginoso\\\n",
        "  Valor 4: asintomático\n",
        "* trtbps: presión arterial en reposo (en mm Hg)\n",
        "* chol: colestoral en mg/dl obtenido a través del sensor BMI\n",
        "* fbs: (azúcar en sangre en ayunas > 120 mg/dl) (1 = verdadero; 0 = falso)\n",
        "* rest_ecg : resultados electrocardiográficos en reposo\\\n",
        "  Valor 0: normal\\\n",
        "  Valor 1: tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST > 0,05 mV)\\\n",
        "  Valor 2: mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes\\\n",
        "* thalach: frecuencia cardíaca máxima alcanzada\n",
        "* objetivo: 0= menos posibilidades de ataque al corazón 1= más posibilidades de ataque al corazón\n",
        "\n",
        "link de kaggle dataset.\n",
        "https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "SW6BUdJMuELi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "UfyoNSW76enu",
        "outputId": "fd0a2974-2437-4926-d430-6d16818ecbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-10711b31-eff2-4726-9de1-b5d25cf1e503\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-10711b31-eff2-4726-9de1-b5d25cf1e503\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart.csv to heart (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerias"
      ],
      "metadata": {
        "id": "gzXfo7avTLPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import io \n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "np.random.seed(7)\n",
        "df = pd.read_csv(io.BytesIO(uploaded['heart.csv'])) \n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNG0EeKc8wxK",
        "outputId": "80c3aa4c-eb4f-4946-9454-540b779ee59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
            "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
            "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
            "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
            "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
            "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
            "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
            "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
            "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
            "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
            "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
            "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
            "\n",
            "     caa  thall  output  \n",
            "0      0      1       1  \n",
            "1      0      2       1  \n",
            "2      0      2       1  \n",
            "3      0      2       1  \n",
            "4      0      2       1  \n",
            "..   ...    ...     ...  \n",
            "298    0      3       0  \n",
            "299    0      3       0  \n",
            "300    2      3       0  \n",
            "301    1      3       0  \n",
            "302    1      2       0  \n",
            "\n",
            "[303 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMGjiniZ__d9",
        "outputId": "8c3c9590-39b8-4fba-d60b-e072989cb33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age           int64\n",
              "sex           int64\n",
              "cp            int64\n",
              "trtbps        int64\n",
              "chol          int64\n",
              "fbs           int64\n",
              "restecg       int64\n",
              "thalachh      int64\n",
              "exng          int64\n",
              "oldpeak     float64\n",
              "slp           int64\n",
              "caa           int64\n",
              "thall         int64\n",
              "output        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "B1u8m06iCssR",
        "outputId": "80faf9ab-6831-4487-a27d-892bfa81d542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
              "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
              "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
              "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
              "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
              "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
              "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
              "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
              "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
              "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
              "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
              "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
              "\n",
              "     caa  thall  \n",
              "0      0      1  \n",
              "1      0      2  \n",
              "2      0      2  \n",
              "3      0      2  \n",
              "4      0      2  \n",
              "..   ...    ...  \n",
              "298    0      3  \n",
              "299    0      3  \n",
              "300    2      3  \n",
              "301    1      3  \n",
              "302    1      2  \n",
              "\n",
              "[303 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87f26175-23c7-458c-b664-40e1f10a3bc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87f26175-23c7-458c-b664-40e1f10a3bc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87f26175-23c7-458c-b664-40e1f10a3bc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87f26175-23c7-458c-b664-40e1f10a3bc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.iloc[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVVGskHpEWOu",
        "outputId": "8ae55b3c-ec14-42a0-aab5-8f4710becce3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "298    0\n",
              "299    0\n",
              "300    0\n",
              "301    0\n",
              "302    0\n",
              "Name: output, Length: 303, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A CONTINUACION, SE OBSERVA EL NUMERO DE SALIDAS\\\n",
        "0= menos posibilidades de ataque al corazón 1= más posibilidades de ataque al corazón"
      ],
      "metadata": {
        "id": "OtxC87mUTd_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.hist()\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iGp1gOp_Sdl_",
        "outputId": "9312464a-69fc-47de-e55e-0fef059aee33"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT8UlEQVR4nO3df5Bd9Xnf8fcnoti1NpGwVe9QSa3kBqcl0LSwJWQ8k+6GTCLjjMVMPR4Y3IgMU41t4jK1M7Yc/0GnHWagHeLa2E2rBEZyTVkIdSMFTBpC2DLJRDiSTVh+2LGCZVsqleIKtl2bYBM//eOebXfklXb33r33smffrxmN7vmec+73eXalj46+e+69qSokSe3yQ8MuQJK08gx3SWohw12SWshwl6QWMtwlqYXOG3YBAJs2bapt27Z1de63v/1t1q9fv7IFvcbZ89pgz2tDLz0fOXLkW1X1Nxba95oI923btnH48OGuzp2ammJ8fHxlC3qNs+e1wZ7Xhl56TvL1s+1zWUaSWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJa6DXxClVJGqZtex4a2tz7dvTn7Ra8cpekFjLcJamFFg33JHcnOZXk6TPGP5Dky0meSfJv5o1/NMnRJF9J8vP9KFqSdG5LWXPfB3wK+MzcQJIJYCfwE1X1SpI3N+MXA9cCPw78TeD3k7y1qv5qpQuXJJ3dolfuVfU4cPqM4fcBt1XVK80xp5rxncBkVb1SVV8DjgJXrGC9kqQlSFUtflCyDXiwqi5ptp8EDgA7gL8EfqWq/iTJp4BDVfXZ5ri7gIer6oEFnnM3sBtgdHT08snJya4amJ2dZWRkpKtzVyt7XhvseXCmT8wMfM452zes67rniYmJI1U1ttC+bm+FPA94I3Al8I+A+5O8ZTlPUFV7gb0AY2Nj1e2b1fvm/muDPa8Nw+r5hiHfCtmPnru9W+Y48Lnq+ALwfWATcALYOu+4Lc2YJGmAug333wYmAJK8FTgf+BZwELg2yeuSbAcuAr6wEoVKkpZu0WWZJPcC48CmJMeBW4C7gbub2yO/C+yqzuL9M0nuB54FXgVu8k4ZSRq8RcO9qq47y673nOX4W4FbeylKktQbX6EqSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktdCi4Z7k7iSnmk9dOnPfh5JUkk3NdpJ8MsnRJE8luawfRUuSzm0pV+77gB1nDibZCvwc8I15w2+n87mpFwG7gV/vvURJ0nItGu5V9ThweoFdHwc+DNS8sZ3AZ6rjELAxyYUrUqkkackW/QzVhSTZCZyoqj9NMn/XZuCb87aPN2MvLPAcu+lc3TM6OsrU1FQ3pTA7O9v1uauVPa8N9jw4H7r01YHPOadfPS873JO8AfhVOksyXauqvcBegLGxsRofH+/qeaampuj23NXKntcGex6cG/Y8NPA55+zbsb4vPXdz5f53gO3A3FX7FuCLSa4ATgBb5x27pRmTJA3QssO9qqaBN89tJzkGjFXVt5IcBH45ySTwk8BMVf3AksxKmj4xM7R/dY/d9o6hzCtJi1nKrZD3An8M/FiS40luPMfhnweeB44CvwG8f0WqlCQty6JX7lV13SL7t817XMBNvZclSeqFr1CVpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWmgpn8R0d5JTSZ6eN/Zvk3w5yVNJ/muSjfP2fTTJ0SRfSfLz/SpcknR2S7ly3wfsOGPsEeCSqvr7wJ8BHwVIcjFwLfDjzTn/Psm6FatWkrQki4Z7VT0OnD5j7Peq6tVm8xCwpXm8E5isqleq6mt0Pkv1ihWsV5K0BOl87OkiByXbgAer6pIF9v0OcF9VfTbJp4BDVfXZZt9dwMNV9cAC5+0GdgOMjo5ePjk52VUDp07PcPLlrk7t2aWbNwxl3tnZWUZGRoYy97DY89owrJ6nT8wMfM452zes67rniYmJI1U1ttC+RT8g+1ySfAx4FbhnuedW1V5gL8DY2FiNj493VcOd9xzgjume2ujasevHhzLv1NQU3X69Vit7XhuG1fMNex4a+Jxz9u1Y35eeu07FJDcAvwBcVf//8v8EsHXeYVuaMUnSAHV1K2SSHcCHgXdW1Xfm7ToIXJvkdUm2AxcBX+i9TEnScix65Z7kXmAc2JTkOHALnbtjXgc8kgQ66+zvrapnktwPPEtnueamqvqrfhUvSVrYouFeVdctMHzXOY6/Fbi1l6IkSb3xFaqS1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EKGuyS1kOEuSS1kuEtSCy0a7knuTnIqydPzxt6Y5JEkX21+v6AZT5JPJjma5Kkkl/WzeEnSwpZy5b4P2HHG2B7g0aq6CHi02QZ4O53PTb0I2A38+sqUKUlajkXDvaoeB06fMbwT2N883g9cM2/8M9VxCNiY5MKVKlaStDSpqsUPSrYBD1bVJc32S1W1sXkc4MWq2pjkQeC2qvrDZt+jwEeq6vACz7mbztU9o6Ojl09OTnbVwKnTM5x8uatTe3bp5g1DmXd2dpaRkZGhzD0s9rw2DKvn6RMzA59zzvYN67rueWJi4khVjS20b9EPyF5MVVWSxf+F+MHz9gJ7AcbGxmp8fLyr+e+85wB3TPfcRleOXT8+lHmnpqbo9uu1Wtnz2jCsnm/Y89DA55yzb8f6vvTc7d0yJ+eWW5rfTzXjJ4Ct847b0oxJkgao23A/COxqHu8CDswb/8XmrpkrgZmqeqHHGiVJy7ToekaSe4FxYFOS48AtwG3A/UluBL4OvLs5/PPA1cBR4DvAL/WhZknSIhYN96q67iy7rlrg2AJu6rUoSVJvfIWqJLWQ4S5JLWS4S1ILGe6S1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EI9hXuSf5HkmSRPJ7k3yeuTbE/yRJKjSe5Lcv5KFStJWpquwz3JZuCfA2NVdQmwDrgWuB34eFX9KPAicONKFCpJWrpel2XOA/56kvOANwAvAD8DPNDs3w9c0+MckqRlSudjT7s8ObkZuBV4Gfg94GbgUHPVTpKtwMPNlf2Z5+4GdgOMjo5ePjk52VUNp07PcPLl7urv1aWbNwxl3tnZWUZGRoYy97DY89owrJ6nT8wMfM452zes67rniYmJI1U1ttC+RT8g+2ySXADsBLYDLwG/BexY6vlVtRfYCzA2Nlbj4+Nd1XHnPQe4Y7rrNnpy7Prxocw7NTVFt1+v1cqe14Zh9XzDnocGPuecfTvW96XnXpZlfhb4WlX9RVV9D/gc8DZgY7NMA7AFONFjjZKkZeol3L8BXJnkDUkCXAU8CzwGvKs5ZhdwoLcSJUnL1XW4V9UTdH5w+kVgunmuvcBHgA8mOQq8CbhrBeqUJC1DT4vVVXULcMsZw88DV/TyvJKk3vgKVUlqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFegr3JBuTPJDky0meS/JTSd6Y5JEkX21+v2ClipUkLU2vV+6fAH63qv4u8BPAc8Ae4NGqugh4tNmWJA1Q1+GeZAPw0zSfkVpV362ql4CdwP7msP3ANb0WKUlanlRVdycm/4DOB2I/S+eq/QhwM3CiqjY2xwR4cW77jPN3A7sBRkdHL5+cnOyqjlOnZzj5clen9uzSzRuGMu/s7CwjIyNDmXtY7HltGFbP0ydmBj7nnO0b1nXd88TExJGqGltoXy/hPgYcAt5WVU8k+QTwv4EPzA/zJC9W1TnX3cfGxurw4cNd1XHnPQe4Y7qnz/nu2rHb3jGUeaemphgfHx/K3MNiz2vDsHretuehgc85Z9+O9V33nOSs4d7Lmvtx4HhVPdFsPwBcBpxMcmEz8YXAqR7mkCR1oetwr6r/CXwzyY81Q1fRWaI5COxqxnYBB3qqUJK0bL2uZ3wAuCfJ+cDzwC/R+Qfj/iQ3Al8H3t3jHJKkZeop3KvqSWCh9Z6renleSVJvfIWqJLWQ4S5JLWS4S1ILGe6S1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EI9h3uSdUm+lOTBZnt7kieSHE1yX/MpTZKkAVqJK/ebgefmbd8OfLyqfhR4EbhxBeaQJC1DT+GeZAvwDuA3m+0APwM80ByyH7imlzkkScvX65X7vwM+DHy/2X4T8FJVvdpsHwc29ziHJGmZUlXdnZj8AnB1Vb0/yTjwK8ANwKFmSYYkW4GHq+qSBc7fDewGGB0dvXxycrKrOk6dnuHky12d2rNLN28Yyryzs7OMjIwMZe5hsee1YVg9T5+YGficc7ZvWNd1zxMTE0eqamyhfef1UNPbgHcmuRp4PfAjwCeAjUnOa67etwAnFjq5qvYCewHGxsZqfHy8qyLuvOcAd0z30kb3jl0/PpR5p6am6PbrtVrZ89owrJ5v2PPQwOecs2/H+r703PWyTFV9tKq2VNU24FrgD6rqeuAx4F3NYbuAAz1XKUlaln7c5/4R4INJjtJZg7+rD3NIks5hRdYzqmoKmGoePw9csRLPK0nqjq9QlaQWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFuo63JNsTfJYkmeTPJPk5mb8jUkeSfLV5vcLVq5cSdJS9HLl/irwoaq6GLgSuCnJxcAe4NGqugh4tNmWJA1Q1+FeVS9U1Rebx/8HeA7YDOwE9jeH7Qeu6bVISdLypKp6f5JkG/A4cAnwjara2IwHeHFu+4xzdgO7AUZHRy+fnJzsau5Tp2c4+XJ3dffq0s0bhjLv7OwsIyMjQ5l7WOx5bRhWz9MnZgY+55ztG9Z13fPExMSRqhpbaF/P4Z5kBPjvwK1V9bkkL80P8yQvVtU5193Hxsbq8OHDXc1/5z0HuGP6vK7O7dWx294xlHmnpqYYHx8fytzDYs9rw7B63rbnoYHPOWffjvVd95zkrOHe090ySf4a8F+Ae6rqc83wySQXNvsvBE71Mockafl6uVsmwF3Ac1X1a/N2HQR2NY93AQe6L0+S1I1e1jPeBvxTYDrJk83YrwK3AfcnuRH4OvDu3kqUJC1X1+FeVX8I5Cy7r+r2eSVJvfMVqpLUQoa7JLWQ4S5JLWS4S1ILGe6S1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1IL9S3ck+xI8pUkR5Ps6dc8kqQf1JdwT7IO+DTwduBi4LokF/djLknSD+rXlfsVwNGqer6qvgtMAjv7NJck6Qy9fED2uWwGvjlv+zjwk/MPSLIb2N1szib5SpdzbQK+1eW5Pcntw5gVGGLPQ2TPa8Oa63ni9p56/ttn29GvcF9UVe0F9vb6PEkOV9XYCpS0atjz2mDPa0O/eu7XsswJYOu87S3NmCRpAPoV7n8CXJRke5LzgWuBg32aS5J0hr4sy1TVq0l+GfhvwDrg7qp6ph9zsQJLO6uQPa8N9rw29KXnVFU/nleSNES+QlWSWshwl6QWWjXhvtjbGSR5XZL7mv1PJNk2+CpX1hJ6/mCSZ5M8leTRJGe953W1WOrbViT5J0kqyaq/bW4pPSd5d/O9fibJfx50jSttCX+2/1aSx5J8qfnzffUw6lwpSe5OcirJ02fZnySfbL4eTyW5rOdJq+o1/4vOD2X/HHgLcD7wp8DFZxzzfuA/NI+vBe4bdt0D6HkCeEPz+H1roefmuB8GHgcOAWPDrnsA3+eLgC8BFzTbbx523QPoeS/wvubxxcCxYdfdY88/DVwGPH2W/VcDDwMBrgSe6HXO1XLlvpS3M9gJ7G8ePwBclSQDrHGlLdpzVT1WVd9pNg/ReT3BarbUt63418DtwF8Osrg+WUrP/wz4dFW9CFBVpwZc40pbSs8F/EjzeAPwPwZY34qrqseB0+c4ZCfwmeo4BGxMcmEvc66WcF/o7Qw2n+2YqnoVmAHeNJDq+mMpPc93I51/+VezRXtu/ru6taoeGmRhfbSU7/Nbgbcm+aMkh5LsGFh1/bGUnv8l8J4kx4HPAx8YTGlDs9y/74sa2tsPaOUkeQ8wBvzjYdfST0l+CPg14IYhlzJo59FZmhmn87+zx5NcWlUvDbWq/roO2FdVdyT5KeA/Jbmkqr4/7MJWi9Vy5b6UtzP4f8ckOY/Of+X+10Cq648lvYVDkp8FPga8s6peGVBt/bJYzz8MXAJMJTlGZ23y4Cr/oepSvs/HgYNV9b2q+hrwZ3TCfrVaSs83AvcDVNUfA6+n86ZibbXib9myWsJ9KW9ncBDY1Tx+F/AH1fykYpVatOck/xD4j3SCfbWvw8IiPVfVTFVtqqptVbWNzs8Z3llVh4dT7opYyp/t36Zz1U6STXSWaZ4fZJErbCk9fwO4CiDJ36MT7n8x0CoH6yDwi81dM1cCM1X1Qk/POOyfIi/jp81X07li+XPgY83Yv6Lzlxs63/zfAo4CXwDeMuyaB9Dz7wMngSebXweHXXO/ez7j2ClW+d0yS/w+h85y1LPANHDtsGseQM8XA39E506aJ4GfG3bNPfZ7L/AC8D06/xO7EXgv8N553+NPN1+P6ZX4c+3bD0hSC62WZRlJ0jIY7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EKGuyS10P8FYTxxUNHbWGEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# División de los datos en train y test\n",
        "# ==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                       X,\n",
        "                                       y,\n",
        "                                        train_size   = 0.6,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Riq0_HC0FUOP",
        "outputId": "a4197ef5-f39c-4196-cf63-392c8921c3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((181, 13), (122, 13), (181,), (122,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CON METROS CUADRADOS ORDINARIOS Y RIDGE SE VAN A SELECIONAR LAS COLUMNAS CON LAS QUE SE VA A TRABAJAR**"
      ],
      "metadata": {
        "id": "ik4BI59wvicL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mínimos cuadrados ordinarios (OLS)"
      ],
      "metadata": {
        "id": "7f_SYZkPs4v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo\n",
        "# ==============================================================================\n",
        "modelo = LinearRegression(normalize=True)\n",
        "modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "8kV-LDErOMZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827cd531-79b3-40cf-98e7-3082c4c4fd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(normalize=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficientes del modelo\n",
        "# ==============================================================================\n",
        "fig, ax = plt.subplots(figsize=(11, 3.84))\n",
        "ax.bar(range(13),modelo.coef_.flatten())\n",
        "ax.set_xlabel('variable')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "mxgF_f8HO_tU",
        "outputId": "647cf0fe-7901-4142-fadb-8d7b586ef326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "# ==============================================================================\n",
        "predicciones = modelo.predict(X=X_test)\n",
        "predicciones = predicciones.flatten()\n",
        "predicciones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw_k7XSGPOk7",
        "outputId": "26aae499-b1db-42cd-ba06-c95023adb86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.38783614,  0.60082571,  0.53917448,  0.08989162,  0.30489714,\n",
              "        0.93505236,  0.56079557,  0.70835248,  0.10862435,  0.59245919,\n",
              "        0.66071189, -0.22727909, -0.01627854,  0.93745471, -0.07836774,\n",
              "        0.56839046,  0.69782396,  1.02188183,  0.62432365,  0.93349729,\n",
              "        0.80385092,  0.79902283,  0.54528735,  0.21045247,  0.62219084,\n",
              "        0.98176587,  0.23476372,  0.73806579,  0.92420154,  0.82686032,\n",
              "        0.54271135,  1.00746145,  0.79274811,  0.05314534,  0.22339575,\n",
              "        0.14603442,  0.64866764,  0.9054037 ,  0.85208508,  0.67785823,\n",
              "        0.68151035, -0.03069665,  0.79806193,  0.6647969 ,  0.91459921,\n",
              "        0.58710028,  0.52849035,  0.13248498,  0.17985137,  0.09075504,\n",
              "        0.50014186,  0.34281774,  0.96608771,  0.26623845,  0.21126248,\n",
              "        0.73435712,  0.53917448,  0.55366187,  0.52892783,  0.25832073,\n",
              "        0.28585078,  0.18949494, -0.16925962,  0.9075685 ,  0.62704446,\n",
              "        0.90469607,  1.16254697,  1.06798623,  0.50786826,  1.26837722,\n",
              "        1.00552581,  0.12726999,  0.56958282,  0.67589767,  0.69250795,\n",
              "        0.28041163,  0.59887141,  0.67111663,  0.54271446,  0.32611906,\n",
              "        0.14514732,  0.30340634,  0.31294592,  0.87571189,  0.52900996,\n",
              "        0.75374836,  0.5400831 , -0.10862341,  0.33129572,  0.85647608,\n",
              "        0.72078717,  0.69335901,  0.97340325,  0.32328842,  1.04084774,\n",
              "        1.13684493,  0.37468301,  0.50981489,  0.88336185,  0.74802997,\n",
              "       -0.02695337,  0.95061652, -0.14714516,  0.69330046,  0.85131467,\n",
              "        0.45761447,  0.59262157,  0.09117114,  0.81167335,  1.20266906,\n",
              "        0.9916948 ,  0.93294606,  0.58338903,  0.39394644,  0.92330251,\n",
              "        0.26416138,  0.52305909,  0.94125761,  0.25243471,  0.43885717,\n",
              "        0.91891625,  0.74731751])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo \n",
        "# ==============================================================================\n",
        "rmse_ols = mean_squared_error(\n",
        "            y_true  = y_test,\n",
        "            y_pred  = predicciones,\n",
        "            squared = False\n",
        "           )\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_ols}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyFhrH4kPcyd",
        "outputId": "39e69473-0e78-4688-ce12-6cda63641b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El error (rmse) de test es: 0.3868113331464546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge (Cresta)"
      ],
      "metadata": {
        "id": "67RWNBw-wDy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo (con búsqueda por CV del valor óptimo alpha)\n",
        "# ==============================================================================\n",
        "# Por defecto RidgeCV utiliza el mean squared error\n",
        "modelo = RidgeCV(\n",
        "            alphas          = np.logspace(-10, 2, 200),\n",
        "            fit_intercept   = True,\n",
        "            normalize       = True,\n",
        "            store_cv_values = True\n",
        "         )\n",
        "\n",
        "_ = modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "dGxcSndIQFVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a5ad61-6e57-4693-86a7-0ee4d4df1e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución de los coeficientes en función de alpha\n",
        "# ==============================================================================\n",
        "alphas = modelo.alphas\n",
        "coefs = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    modelo_temp = Ridge(alpha=alpha, fit_intercept=False, normalize=True)\n",
        "    modelo_temp.fit(X_train, y_train)\n",
        "    coefs.append(modelo_temp.coef_.flatten())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(alphas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo en función de la regularización');\n",
        "plt.axis('tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BpIexb7iQKzk",
        "outputId": "5d3a0d7f-4d71-4a8d-f115-bc6960b3db63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución del error en función de alpha\n",
        "# ==============================================================================\n",
        "# modelo.cv_values almacena el mse de cv para cada valor de alpha. Tiene\n",
        "# dimensiones (n_samples, n_targets, n_alphas)\n",
        "mse_cv = modelo.cv_values_.reshape((-1, 200)).mean(axis=0)\n",
        "mse_sd = modelo.cv_values_.reshape((-1, 200)).std(axis=0)\n",
        "\n",
        "# Se aplica la raíz cuadrada para pasar de mse a rmse\n",
        "rmse_cv = np.sqrt(mse_cv)\n",
        "rmse_sd = np.sqrt(mse_sd)\n",
        "\n",
        "# Se identifica el óptimo y el óptimo + 1std\n",
        "min_rmse     = np.min(rmse_cv)\n",
        "sd_min_rmse  = rmse_sd[np.argmin(rmse_cv)]\n",
        "min_rsme_1sd = np.max(rmse_cv[rmse_cv <= min_rmse + sd_min_rmse])\n",
        "optimo       = modelo.alphas[np.argmin(rmse_cv)]\n",
        "optimo_1sd   = modelo.alphas[rmse_cv == min_rsme_1sd]\n",
        "\n",
        "\n",
        "# Gráfico del error +- 1 desviación estándar\n",
        "############################################\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(modelo.alphas, rmse_cv)\n",
        "ax.fill_between(\n",
        "    modelo.alphas,\n",
        "    rmse_cv + rmse_sd,\n",
        "    rmse_cv - rmse_sd,\n",
        "    alpha=0.2\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x         = optimo,\n",
        "    c         = \"gray\",\n",
        "    linestyle = '--',\n",
        "    label     = 'óptimo'\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x         = optimo_1sd,\n",
        "    c         = \"blue\",\n",
        "    linestyle = '--',\n",
        "    label     = 'óptimo_1sd'\n",
        ")\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([0,None])\n",
        "ax.set_title('Evolución del error CV en función de la regularización')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('RMSE')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "YHofV3I3QUPt",
        "outputId": "7e6c3619-60b6-4860-d1f3-c0b3ae096a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor valor alpha encontrado\n",
        "# ==============================================================================\n",
        "print(f\"Mejor valor de alpha encontrado: {modelo.alpha_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv8ctoGdwzX2",
        "outputId": "e4a3c73e-71e1-473a-c17c-49196fa95370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor valor de alpha encontrado: 0.33700643292719246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficientes del modelo\n",
        "# ==============================================================================\n",
        "fig, ax = plt.subplots(figsize=(11, 3.84))\n",
        "ax.bar(range(13),modelo.coef_.flatten())\n",
        "ax.set_xlabel('variable')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "5gLBwqCaw4qz",
        "outputId": "84b05a48-7186-4b0d-c992-6418ed59687d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "# ==============================================================================\n",
        "predicciones = modelo.predict(X=X_test)\n",
        "predicciones = predicciones.flatten()\n",
        "predicciones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNOuFMClxDxe",
        "outputId": "7e4b0040-c2a8-48b7-e2b6-1cb663a04f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.39859054,  0.60699217,  0.58565056,  0.13999531,  0.31200534,\n",
              "        0.878105  ,  0.55013225,  0.70480805,  0.17448005,  0.60776037,\n",
              "        0.64893622, -0.13414098,  0.03832708,  0.8923778 , -0.01391406,\n",
              "        0.53886572,  0.67770028,  0.95231996,  0.61472081,  0.88088718,\n",
              "        0.79373904,  0.78149957,  0.54917433,  0.24064149,  0.60916727,\n",
              "        0.914578  ,  0.28013755,  0.73286092,  0.89327172,  0.78351199,\n",
              "        0.56118403,  0.97481121,  0.74714635,  0.09232252,  0.25837937,\n",
              "        0.20004135,  0.65205002,  0.86436209,  0.83666471,  0.67288502,\n",
              "        0.66088174,  0.03797102,  0.76284731,  0.64956512,  0.89234487,\n",
              "        0.57001765,  0.53616276,  0.17706741,  0.20500213,  0.15784848,\n",
              "        0.54533134,  0.34378983,  0.93467574,  0.3087709 ,  0.25210521,\n",
              "        0.74156243,  0.58565056,  0.55151409,  0.51073778,  0.29999541,\n",
              "        0.33060886,  0.21956722, -0.09188391,  0.84417312,  0.61357454,\n",
              "        0.87737015,  1.090237  ,  1.00406108,  0.5283541 ,  1.18137065,\n",
              "        0.94858501,  0.17792307,  0.5698526 ,  0.67669158,  0.67647142,\n",
              "        0.30499152,  0.61164099,  0.66849706,  0.570027  ,  0.3343287 ,\n",
              "        0.20918765,  0.32460295,  0.35798434,  0.83701439,  0.5425451 ,\n",
              "        0.70880272,  0.54167658, -0.01885923,  0.37112448,  0.8216381 ,\n",
              "        0.70617795,  0.67889864,  0.9432965 ,  0.35742384,  1.00229327,\n",
              "        1.06335046,  0.3992976 ,  0.50719116,  0.86078337,  0.74645673,\n",
              "        0.01844522,  0.90101469, -0.0774057 ,  0.69351139,  0.79228667,\n",
              "        0.47257173,  0.57417791,  0.17742231,  0.780497  ,  1.12647061,\n",
              "        0.93264369,  0.90051574,  0.59199325,  0.4141299 ,  0.86803647,\n",
              "        0.30407469,  0.52008714,  0.9117193 ,  0.28003385,  0.44582857,\n",
              "        0.90134058,  0.70912687])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo \n",
        "# ==============================================================================\n",
        "rmse_ridge = mean_squared_error(\n",
        "                y_true  = y_test,\n",
        "                y_pred  = predicciones,\n",
        "                squared = False\n",
        "             )\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_ridge}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUz4l84ZxG3z",
        "outputId": "fef65fa8-c8bf-4b4b-9716-10daba94b460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El error (rmse) de test es: 0.38526365647633004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los errores de los modelos OLS y RIDGE son los siguientes "
      ],
      "metadata": {
        "id": "Q9FHMyEEyUm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_ols, rmse_ridge,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCrMYu5DyOg4",
        "outputId": "e6821d5e-e04a-40da-851b-a9e42716eacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3868113331464546, 0.38526365647633004)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En conclusion, tanto para bridge como para OLS las colnmnas que se pueden usar son: sex,cp,exng,slp,caa,thall"
      ],
      "metadata": {
        "id": "JEffxm3kyiQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sel=X.iloc[:,[1,2,8,10,11,12]]\n",
        "X_sel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NtJNXsSuy6tk",
        "outputId": "7e86fd41-9726-45c9-b5ae-2862447c566a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  cp  exng  slp  caa  thall\n",
              "0      1   3     0    0    0      1\n",
              "1      1   2     0    0    0      2\n",
              "2      0   1     0    2    0      2\n",
              "3      1   1     0    2    0      2\n",
              "4      0   0     1    2    0      2\n",
              "..   ...  ..   ...  ...  ...    ...\n",
              "298    0   0     1    1    0      3\n",
              "299    1   3     0    1    0      3\n",
              "300    1   0     0    1    2      3\n",
              "301    1   0     1    1    1      3\n",
              "302    0   1     0    1    1      2\n",
              "\n",
              "[303 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e71197b-0096-4957-baa9-5a39ca6a1c5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>exng</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e71197b-0096-4957-baa9-5a39ca6a1c5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e71197b-0096-4957-baa9-5a39ca6a1c5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e71197b-0096-4957-baa9-5a39ca6a1c5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASIFICACIÓN METODO DE VECINOS CERCANOS"
      ],
      "metadata": {
        "id": "_P3G2al6z4EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sel.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "GbEqO-IBz-jX",
        "outputId": "139f0a7a-6ae6-498d-c352-8c115ba9ee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, y_train, y_test = model_selection.train_test_split(X_sel,y, test_size=0.25)\n",
        "X1_train.shape, X1_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "d0pUDscn0ep9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c931d804-dd22-4091-b1cb-4aff935a41f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((227, 6), (76, 6), (227,), (76,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se averigua el mejor K"
      ],
      "metadata": {
        "id": "sX_XS81dt4W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1,181,1):\n",
        "    n_neighbors = k\n",
        "    knn = KNeighborsClassifier(n_neighbors)\n",
        "    knn.fit(X1_train, y_train)\n",
        "    print('Precision en los valores de entrenamiento: {:.2f}'\n",
        "        .format(knn.score(X1_train, y_train)))\n",
        "    print('Precision en los valores de prueba: {:.2f}'\n",
        "        .format(knn.score(X1_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u74Fe6oFlAXR",
        "outputId": "7718c0c6-58ff-4ece-c9d8-029bc1a16b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision en los valores de entrenamiento: 0.93\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.87\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.89\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.87\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.86\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.86\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.88\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.88\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.86\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.84\n",
            "Precision en los valores de prueba: 0.84\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.80\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.82\n",
            "Precision en los valores de entrenamiento: 0.85\n",
            "Precision en los valores de prueba: 0.83\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.83\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.82\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.76\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.79\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.78\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.78\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.75\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.81\n",
            "Precision en los valores de prueba: 0.74\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.79\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.77\n",
            "Precision en los valores de prueba: 0.72\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.76\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.73\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.71\n",
            "Precision en los valores de entrenamiento: 0.72\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.72\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.72\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.74\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.71\n",
            "Precision en los valores de prueba: 0.67\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 84% en el set de entrenamiento y del 84% para el de test para K=25."
      ],
      "metadata": {
        "id": "2CKNHm9kzD-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=25)\n",
        "clf.fit(X1_train, y_train)\n",
        "print(clf.predict_proba([[1,3,0,0,0,1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHq6qT7vteuP",
        "outputId": "61db11b1-83f3-420f-a46f-8a7bbdeb6eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24 0.76]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 76% de probabilidad que tenga un paro cardiaco y el 24% que no tenga paro cardiaco"
      ],
      "metadata": {
        "id": "6ihTu89Td9C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = clf.predict(X1_train)\n",
        "print(confusion_matrix(y_train, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT18b-o6k-Rw",
        "outputId": "7fe6c36f-4d5d-4e08-b3c3-525015cd4c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 74  25]\n",
            " [ 11 117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASIFICADOR BAYESIANO INGENUO**"
      ],
      "metadata": {
        "id": "0fBOe4rAnrI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = GaussianNB()\n",
        "clf1.fit(X1_train, y_train)\n",
        "print(clf1.predict_proba([[1,3,0,0,0,1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxbflvNnxMX",
        "outputId": "afe0aa77-35a6-4771-ee28-15b3ea5114d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.08246541 0.91753459]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 91.75% de probabilidad que tenga un paro cardiaco y el 8.24% que no tenga paro cardiaco\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R9DPrAA_tZW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train, clf1.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZrrPCcgt2W2",
        "outputId": "0e530c4f-7660-47c8-bd19-809d49033236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370044052863436"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_train, clf1.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7JtRUBTw1N9",
        "outputId": "0a1b3c88-07a4-4215-e8a7-c524a04baa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 78,  21],\n",
              "       [ 16, 112]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, clf1.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpRwm1aI2m2r",
        "outputId": "2e2858ce-f7cc-4cf6-db52-ca1357ca632d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8026315789473685"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, clf1.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5TJjJ1y6EhD",
        "outputId": "fe6b5e6c-ec50-4efa-f8c1-0c83323e130b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29, 10],\n",
              "       [ 5, 32]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 83.7% en el set de entrenamiento y del 80.26% para el de test"
      ],
      "metadata": {
        "id": "vzxHH9q56aEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASIFICADOR REDES NEURONALES**"
      ],
      "metadata": {
        "id": "hd24YQYcL4SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLPClassifier(hidden_layer_sizes=(8,8,8), max_iter=500, alpha=0.0001,\n",
        "                     solver='adam', random_state=21,tol=0.000000001)\n",
        "mlp.fit(X1_train,y_train)\n",
        "print(mlp.predict_proba([[1,3,0,0,0,1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R264iXvHL82Z",
        "outputId": "344db4d1-7e0c-4471-c18e-f6489aaea15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26999173 0.73000827]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 73% de probabilidad que tenga un paro cardiaco y el 26.99% que no tenga paro cardiaco"
      ],
      "metadata": {
        "id": "h5Ihuw4pOLNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train, mlp.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwmp8yjVNHs5",
        "outputId": "89a55af7-07be-4b46-8dff-3accd3f5f251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8546255506607929"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_train, mlp.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaMUIMdINk5h",
        "outputId": "55b9cb6f-3460-4586-953a-dc83bd56a3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 77,  22],\n",
              "       [ 11, 117]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, mlp.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaT_L_ERNrMY",
        "outputId": "d907fcd2-a717-451c-e394-61c7f3ed55a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8157894736842105"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, mlp.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3RXGIqVNyXI",
        "outputId": "6d08be5b-8605-4d5d-c3a5-92390cdb3ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30,  9],\n",
              "       [ 5, 32]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 85.46% en el set de entrenamiento y del 81.57% para el de test"
      ],
      "metadata": {
        "id": "ctNTYaEbOcjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\\\n",
        "Lo que se puedo observar es que el clasificador de redes neuronales tiene un 85.46% de proximidad en entrenamiento y el mejor clasificador para el test es el de vecino cercanos con K=25 y una proximidad del 84%.\n"
      ],
      "metadata": {
        "id": "GhCmJrjkX1d1"
      }
    }
  ]
}