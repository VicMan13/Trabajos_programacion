{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MULTIPLES CLASIFICADORES PARA UNA BASE DE DATOS PARA PREDECIR UN ATAQUE CARDIACO**"
      ],
      "metadata": {
        "id": "fpqiuPTuS8dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conjunto de datos de análisis y predicción de ataques cardíacos\n",
        "* age : Edad del paciente\n",
        "* Sex : Sexo del paciente\n",
        "* exang: angina inducida por el ejercicio (1 = sí; 0 = no)\n",
        "* ca: número de buques principales (0-3)\n",
        "* cp : Tipo de dolor torácico tipo de dolor torácico\\\n",
        "  Valor 1: angina típica\\\n",
        "  Valor 2: angina atípica\\\n",
        "  Valor 3: dolor no anginoso\\\n",
        "  Valor 4: asintomático\n",
        "* trtbps: presión arterial en reposo (en mm Hg)\n",
        "* chol: colestoral en mg/dl obtenido a través del sensor BMI\n",
        "* fbs: (azúcar en sangre en ayunas > 120 mg/dl) (1 = verdadero; 0 = falso)\n",
        "* rest_ecg : resultados electrocardiográficos en reposo\\\n",
        "  Valor 0: normal\\\n",
        "  Valor 1: tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST > 0,05 mV)\\\n",
        "  Valor 2: mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes\\\n",
        "* thalach: frecuencia cardíaca máxima alcanzada\n",
        "* objetivo: 0= menos posibilidades de ataque al corazón 1= más posibilidades de ataque al corazón\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SW6BUdJMuELi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UfyoNSW76enu",
        "outputId": "dab7b7ac-75b5-4834-e4cb-8376d6a2557a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b123b471-9ea4-4241-b468-954f1fe2c73d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b123b471-9ea4-4241-b468-954f1fe2c73d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart.csv to heart.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerias"
      ],
      "metadata": {
        "id": "gzXfo7avTLPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import io \n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "np.random.seed(7)\n",
        "df = pd.read_csv(io.BytesIO(uploaded['heart.csv'])) \n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNG0EeKc8wxK",
        "outputId": "56d4a976-89b6-4d8c-ea2d-9cc7119b30df"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
            "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
            "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
            "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
            "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
            "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
            "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
            "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
            "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
            "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
            "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
            "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
            "\n",
            "     caa  thall  output  \n",
            "0      0      1       1  \n",
            "1      0      2       1  \n",
            "2      0      2       1  \n",
            "3      0      2       1  \n",
            "4      0      2       1  \n",
            "..   ...    ...     ...  \n",
            "298    0      3       0  \n",
            "299    0      3       0  \n",
            "300    2      3       0  \n",
            "301    1      3       0  \n",
            "302    1      2       0  \n",
            "\n",
            "[303 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMGjiniZ__d9",
        "outputId": "885f693e-b851-479d-83ad-df932c8e2a88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age           int64\n",
              "sex           int64\n",
              "cp            int64\n",
              "trtbps        int64\n",
              "chol          int64\n",
              "fbs           int64\n",
              "restecg       int64\n",
              "thalachh      int64\n",
              "exng          int64\n",
              "oldpeak     float64\n",
              "slp           int64\n",
              "caa           int64\n",
              "thall         int64\n",
              "output        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "B1u8m06iCssR",
        "outputId": "c394ad5b-5d0d-49ce-c619-51a8bdf45793"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
              "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
              "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
              "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
              "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
              "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
              "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
              "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
              "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
              "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
              "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
              "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
              "\n",
              "     caa  thall  \n",
              "0      0      1  \n",
              "1      0      2  \n",
              "2      0      2  \n",
              "3      0      2  \n",
              "4      0      2  \n",
              "..   ...    ...  \n",
              "298    0      3  \n",
              "299    0      3  \n",
              "300    2      3  \n",
              "301    1      3  \n",
              "302    1      2  \n",
              "\n",
              "[303 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97ea04fe-66c2-439b-9905-4870f69a4a6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97ea04fe-66c2-439b-9905-4870f69a4a6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97ea04fe-66c2-439b-9905-4870f69a4a6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97ea04fe-66c2-439b-9905-4870f69a4a6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.iloc[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVVGskHpEWOu",
        "outputId": "0f5fbba6-c024-4938-e25c-a6043eac7bc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "298    0\n",
              "299    0\n",
              "300    0\n",
              "301    0\n",
              "302    0\n",
              "Name: output, Length: 303, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# División de los datos en train y test\n",
        "# ==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                       X,\n",
        "                                       y,\n",
        "                                        train_size   = 0.6,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Riq0_HC0FUOP",
        "outputId": "c5c2bf7d-ad3e-47a2-f754-c58ce17dc8a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((181, 13), (122, 13), (181,), (122,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccion de las columnas"
      ],
      "metadata": {
        "id": "ik4BI59wvicL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mínimos cuadrados ordinarios (OLS)"
      ],
      "metadata": {
        "id": "7f_SYZkPs4v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo\n",
        "# ==============================================================================\n",
        "modelo = LinearRegression(normalize=True)\n",
        "modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "8kV-LDErOMZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficientes del modelo\n",
        "# ==============================================================================\n",
        "fig, ax = plt.subplots(figsize=(11, 3.84))\n",
        "ax.bar(range(13),modelo.coef_.flatten())\n",
        "ax.set_xlabel('variable')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "mxgF_f8HO_tU",
        "outputId": "6b8bf7fb-357f-454c-94fa-237f10097fa2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "# ==============================================================================\n",
        "predicciones = modelo.predict(X=X_test)\n",
        "predicciones = predicciones.flatten()\n",
        "predicciones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw_k7XSGPOk7",
        "outputId": "5ddbce1d-9d92-46db-aafc-fef140fb1e48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.38783614,  0.60082571,  0.53917448,  0.08989162,  0.30489714,\n",
              "        0.93505236,  0.56079557,  0.70835248,  0.10862435,  0.59245919,\n",
              "        0.66071189, -0.22727909, -0.01627854,  0.93745471, -0.07836774,\n",
              "        0.56839046,  0.69782396,  1.02188183,  0.62432365,  0.93349729,\n",
              "        0.80385092,  0.79902283,  0.54528735,  0.21045247,  0.62219084,\n",
              "        0.98176587,  0.23476372,  0.73806579,  0.92420154,  0.82686032,\n",
              "        0.54271135,  1.00746145,  0.79274811,  0.05314534,  0.22339575,\n",
              "        0.14603442,  0.64866764,  0.9054037 ,  0.85208508,  0.67785823,\n",
              "        0.68151035, -0.03069665,  0.79806193,  0.6647969 ,  0.91459921,\n",
              "        0.58710028,  0.52849035,  0.13248498,  0.17985137,  0.09075504,\n",
              "        0.50014186,  0.34281774,  0.96608771,  0.26623845,  0.21126248,\n",
              "        0.73435712,  0.53917448,  0.55366187,  0.52892783,  0.25832073,\n",
              "        0.28585078,  0.18949494, -0.16925962,  0.9075685 ,  0.62704446,\n",
              "        0.90469607,  1.16254697,  1.06798623,  0.50786826,  1.26837722,\n",
              "        1.00552581,  0.12726999,  0.56958282,  0.67589767,  0.69250795,\n",
              "        0.28041163,  0.59887141,  0.67111663,  0.54271446,  0.32611906,\n",
              "        0.14514732,  0.30340634,  0.31294592,  0.87571189,  0.52900996,\n",
              "        0.75374836,  0.5400831 , -0.10862341,  0.33129572,  0.85647608,\n",
              "        0.72078717,  0.69335901,  0.97340325,  0.32328842,  1.04084774,\n",
              "        1.13684493,  0.37468301,  0.50981489,  0.88336185,  0.74802997,\n",
              "       -0.02695337,  0.95061652, -0.14714516,  0.69330046,  0.85131467,\n",
              "        0.45761447,  0.59262157,  0.09117114,  0.81167335,  1.20266906,\n",
              "        0.9916948 ,  0.93294606,  0.58338903,  0.39394644,  0.92330251,\n",
              "        0.26416138,  0.52305909,  0.94125761,  0.25243471,  0.43885717,\n",
              "        0.91891625,  0.74731751])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo \n",
        "# ==============================================================================\n",
        "rmse_ols = mean_squared_error(\n",
        "            y_true  = y_test,\n",
        "            y_pred  = predicciones,\n",
        "            squared = False\n",
        "           )\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_ols}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyFhrH4kPcyd",
        "outputId": "f5eb2ac7-7654-4c97-b0ea-b7292e304b36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El error (rmse) de test es: 0.3868113331464546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge (Cresta)"
      ],
      "metadata": {
        "id": "67RWNBw-wDy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo (con búsqueda por CV del valor óptimo alpha)\n",
        "# ==============================================================================\n",
        "# Por defecto RidgeCV utiliza el mean squared error\n",
        "modelo = RidgeCV(\n",
        "            alphas          = np.logspace(-10, 2, 200),\n",
        "            fit_intercept   = True,\n",
        "            normalize       = True,\n",
        "            store_cv_values = True\n",
        "         )\n",
        "\n",
        "_ = modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "dGxcSndIQFVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución de los coeficientes en función de alpha\n",
        "# ==============================================================================\n",
        "alphas = modelo.alphas\n",
        "coefs = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    modelo_temp = Ridge(alpha=alpha, fit_intercept=False, normalize=True)\n",
        "    modelo_temp.fit(X_train, y_train)\n",
        "    coefs.append(modelo_temp.coef_.flatten())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(alphas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo en función de la regularización');\n",
        "plt.axis('tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BpIexb7iQKzk",
        "outputId": "b96342f0-f711-4725-d103-cfc638724f66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución del error en función de alpha\n",
        "# ==============================================================================\n",
        "# modelo.cv_values almacena el mse de cv para cada valor de alpha. Tiene\n",
        "# dimensiones (n_samples, n_targets, n_alphas)\n",
        "mse_cv = modelo.cv_values_.reshape((-1, 200)).mean(axis=0)\n",
        "mse_sd = modelo.cv_values_.reshape((-1, 200)).std(axis=0)\n",
        "\n",
        "# Se aplica la raíz cuadrada para pasar de mse a rmse\n",
        "rmse_cv = np.sqrt(mse_cv)\n",
        "rmse_sd = np.sqrt(mse_sd)\n",
        "\n",
        "# Se identifica el óptimo y el óptimo + 1std\n",
        "min_rmse     = np.min(rmse_cv)\n",
        "sd_min_rmse  = rmse_sd[np.argmin(rmse_cv)]\n",
        "min_rsme_1sd = np.max(rmse_cv[rmse_cv <= min_rmse + sd_min_rmse])\n",
        "optimo       = modelo.alphas[np.argmin(rmse_cv)]\n",
        "optimo_1sd   = modelo.alphas[rmse_cv == min_rsme_1sd]\n",
        "\n",
        "\n",
        "# Gráfico del error +- 1 desviación estándar\n",
        "############################################\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(modelo.alphas, rmse_cv)\n",
        "ax.fill_between(\n",
        "    modelo.alphas,\n",
        "    rmse_cv + rmse_sd,\n",
        "    rmse_cv - rmse_sd,\n",
        "    alpha=0.2\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x         = optimo,\n",
        "    c         = \"gray\",\n",
        "    linestyle = '--',\n",
        "    label     = 'óptimo'\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x         = optimo_1sd,\n",
        "    c         = \"blue\",\n",
        "    linestyle = '--',\n",
        "    label     = 'óptimo_1sd'\n",
        ")\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([0,None])\n",
        "ax.set_title('Evolución del error CV en función de la regularización')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('RMSE')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "YHofV3I3QUPt",
        "outputId": "340a6123-2fcb-4c54-9a5d-2bd9388084cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor valor alpha encontrado\n",
        "# ==============================================================================\n",
        "print(f\"Mejor valor de alpha encontrado: {modelo.alpha_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv8ctoGdwzX2",
        "outputId": "44d10bed-8fb1-482d-eda3-c9b0f9f7d8bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor valor de alpha encontrado: 0.33700643292719246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficientes del modelo\n",
        "# ==============================================================================\n",
        "fig, ax = plt.subplots(figsize=(11, 3.84))\n",
        "ax.bar(range(13),modelo.coef_.flatten())\n",
        "ax.set_xlabel('variable')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "5gLBwqCaw4qz",
        "outputId": "b459eb82-6880-4099-b32c-73451fd58210"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x276.48 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "# ==============================================================================\n",
        "predicciones = modelo.predict(X=X_test)\n",
        "predicciones = predicciones.flatten()\n",
        "predicciones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNOuFMClxDxe",
        "outputId": "0938f007-22c6-4c2c-f446-bd34498de952"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.39859054,  0.60699217,  0.58565056,  0.13999531,  0.31200534,\n",
              "        0.878105  ,  0.55013225,  0.70480805,  0.17448005,  0.60776037,\n",
              "        0.64893622, -0.13414098,  0.03832708,  0.8923778 , -0.01391406,\n",
              "        0.53886572,  0.67770028,  0.95231996,  0.61472081,  0.88088718,\n",
              "        0.79373904,  0.78149957,  0.54917433,  0.24064149,  0.60916727,\n",
              "        0.914578  ,  0.28013755,  0.73286092,  0.89327172,  0.78351199,\n",
              "        0.56118403,  0.97481121,  0.74714635,  0.09232252,  0.25837937,\n",
              "        0.20004135,  0.65205002,  0.86436209,  0.83666471,  0.67288502,\n",
              "        0.66088174,  0.03797102,  0.76284731,  0.64956512,  0.89234487,\n",
              "        0.57001765,  0.53616276,  0.17706741,  0.20500213,  0.15784848,\n",
              "        0.54533134,  0.34378983,  0.93467574,  0.3087709 ,  0.25210521,\n",
              "        0.74156243,  0.58565056,  0.55151409,  0.51073778,  0.29999541,\n",
              "        0.33060886,  0.21956722, -0.09188391,  0.84417312,  0.61357454,\n",
              "        0.87737015,  1.090237  ,  1.00406108,  0.5283541 ,  1.18137065,\n",
              "        0.94858501,  0.17792307,  0.5698526 ,  0.67669158,  0.67647142,\n",
              "        0.30499152,  0.61164099,  0.66849706,  0.570027  ,  0.3343287 ,\n",
              "        0.20918765,  0.32460295,  0.35798434,  0.83701439,  0.5425451 ,\n",
              "        0.70880272,  0.54167658, -0.01885923,  0.37112448,  0.8216381 ,\n",
              "        0.70617795,  0.67889864,  0.9432965 ,  0.35742384,  1.00229327,\n",
              "        1.06335046,  0.3992976 ,  0.50719116,  0.86078337,  0.74645673,\n",
              "        0.01844522,  0.90101469, -0.0774057 ,  0.69351139,  0.79228667,\n",
              "        0.47257173,  0.57417791,  0.17742231,  0.780497  ,  1.12647061,\n",
              "        0.93264369,  0.90051574,  0.59199325,  0.4141299 ,  0.86803647,\n",
              "        0.30407469,  0.52008714,  0.9117193 ,  0.28003385,  0.44582857,\n",
              "        0.90134058,  0.70912687])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo \n",
        "# ==============================================================================\n",
        "rmse_ridge = mean_squared_error(\n",
        "                y_true  = y_test,\n",
        "                y_pred  = predicciones,\n",
        "                squared = False\n",
        "             )\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_ridge}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUz4l84ZxG3z",
        "outputId": "2f41ee48-f323-4e2f-9a40-540d691f6401"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El error (rmse) de test es: 0.38526365647633004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los errores de los modelos OLS y RIDGE son los siguientes "
      ],
      "metadata": {
        "id": "Q9FHMyEEyUm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_ols, rmse_ridge,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCrMYu5DyOg4",
        "outputId": "8c909e47-864c-4ec1-9c12-52982b233e5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3868113331464546, 0.38526365647633004)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En conclusion, tanto para bridge como para OLS las colnmnas que se pueden usar son: age, trtbps, chol y thalachh."
      ],
      "metadata": {
        "id": "JEffxm3kyiQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sel=X.iloc[:,[0,3,4,7]]\n",
        "X_sel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NtJNXsSuy6tk",
        "outputId": "843e176a-1d2e-4a1b-f4cd-f5a35f6f23aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  trtbps  chol  thalachh\n",
              "0     63     145   233       150\n",
              "1     37     130   250       187\n",
              "2     41     130   204       172\n",
              "3     56     120   236       178\n",
              "4     57     120   354       163\n",
              "..   ...     ...   ...       ...\n",
              "298   57     140   241       123\n",
              "299   45     110   264       132\n",
              "300   68     144   193       141\n",
              "301   57     130   131       115\n",
              "302   57     130   236       174\n",
              "\n",
              "[303 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c620a87-57a0-41e7-9bb3-2e91980a553e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalachh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c620a87-57a0-41e7-9bb3-2e91980a553e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c620a87-57a0-41e7-9bb3-2e91980a553e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c620a87-57a0-41e7-9bb3-2e91980a553e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASIFICACIÓN METODO DE VECINOS CERCANOS"
      ],
      "metadata": {
        "id": "_P3G2al6z4EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sel.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "GbEqO-IBz-jX",
        "outputId": "a0c971df-d218-49f7-9ca4-bb55b377ba44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, y_train, y_test = model_selection.train_test_split(X_sel,y, test_size=0.4)\n",
        "X1_train.shape, X1_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "d0pUDscn0ep9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8450a47f-b788-4e12-823f-0d6ae04fed21"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((181, 4), (122, 4), (181,), (122,))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se averigua el mejor K"
      ],
      "metadata": {
        "id": "sX_XS81dt4W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1,181,1):\n",
        "    n_neighbors = k\n",
        "    knn = KNeighborsClassifier(n_neighbors)\n",
        "    knn.fit(X1_train, y_train)\n",
        "    print('Precision en los valores de entrenamiento: {:.2f}'\n",
        "        .format(knn.score(X1_train, y_train)))\n",
        "    print('Precision en los valores de prueba: {:.2f}'\n",
        "        .format(knn.score(X1_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u74Fe6oFlAXR",
        "outputId": "fbed8d81-c67a-4121-ed5b-8c925b76ca49"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision en los valores de entrenamiento: 1.00\n",
            "Precision en los valores de prueba: 0.56\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.60\n",
            "Precision en los valores de entrenamiento: 0.80\n",
            "Precision en los valores de prueba: 0.58\n",
            "Precision en los valores de entrenamiento: 0.73\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.75\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.73\n",
            "Precision en los valores de prueba: 0.67\n",
            "Precision en los valores de entrenamiento: 0.74\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.73\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.73\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.71\n",
            "Precision en los valores de prueba: 0.67\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.71\n",
            "Precision en los valores de prueba: 0.67\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.72\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.71\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.72\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.69\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.67\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.65\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.70\n",
            "Precision en los valores de prueba: 0.69\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.68\n",
            "Precision en los valores de entrenamiento: 0.71\n",
            "Precision en los valores de prueba: 0.70\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.69\n",
            "Precision en los valores de prueba: 0.65\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.68\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.60\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.67\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.60\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.65\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.66\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.63\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.65\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.65\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.65\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.66\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.62\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.64\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.63\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.64\n",
            "Precision en los valores de entrenamiento: 0.59\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.59\n",
            "Precision en los valores de prueba: 0.62\n",
            "Precision en los valores de entrenamiento: 0.59\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.61\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.60\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.61\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.58\n",
            "Precision en los valores de prueba: 0.57\n",
            "Precision en los valores de entrenamiento: 0.59\n",
            "Precision en los valores de prueba: 0.57\n",
            "Precision en los valores de entrenamiento: 0.57\n",
            "Precision en los valores de prueba: 0.57\n",
            "Precision en los valores de entrenamiento: 0.57\n",
            "Precision en los valores de prueba: 0.57\n",
            "Precision en los valores de entrenamiento: 0.57\n",
            "Precision en los valores de prueba: 0.57\n",
            "Precision en los valores de entrenamiento: 0.57\n",
            "Precision en los valores de prueba: 0.58\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.58\n",
            "Precision en los valores de entrenamiento: 0.57\n",
            "Precision en los valores de prueba: 0.59\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.55\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.56\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.55\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.55\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.55\n",
            "Precision en los valores de entrenamiento: 0.56\n",
            "Precision en los valores de prueba: 0.56\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.54\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.55\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.54\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.54\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n",
            "Precision en los valores de entrenamiento: 0.55\n",
            "Precision en los valores de prueba: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 73% en el set de entrenamiento y del 68% para el de test para K=8."
      ],
      "metadata": {
        "id": "2CKNHm9kzD-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=8)\n",
        "clf.fit(X1_train, y_train)\n",
        "print(clf.predict_proba([[63,145,233,150]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHq6qT7vteuP",
        "outputId": "60aae9b3-4bec-4174-e3d9-ad05487194b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.25 0.75]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 75% de probabilidad que tenga un paro cardiaco y el 25% que no tenga paro cardiaco"
      ],
      "metadata": {
        "id": "6ihTu89Td9C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = clf.predict(X1_train)\n",
        "print(confusion_matrix(y_train, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT18b-o6k-Rw",
        "outputId": "bfe848db-be9d-40ea-d244-d7940167fa36"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[57 24]\n",
            " [24 76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASIFICADOR BAYESIANO INGENUO**"
      ],
      "metadata": {
        "id": "0fBOe4rAnrI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = GaussianNB()\n",
        "clf1.fit(X1_train, y_train)\n",
        "print(clf1.predict_proba([[63,145,233,150]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxbflvNnxMX",
        "outputId": "d2cce40d-e640-4f24-a6b7-7aadd0148845"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.52221254 0.47778746]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 47.77% de probabilidad que tenga un paro cardiaco y el 52.22% que no tenga paro cardiaco\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R9DPrAA_tZW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train, clf1.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZrrPCcgt2W2",
        "outputId": "bcba40f1-7ded-4272-cec7-67a57a2d6216"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7071823204419889"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_train, clf1.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7JtRUBTw1N9",
        "outputId": "fe43aab2-e730-421b-c68e-c9640ae8f42e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52, 29],\n",
              "       [24, 76]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, clf1.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpRwm1aI2m2r",
        "outputId": "5df2c90d-2b52-47b2-ea97-37fee46f8dcf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6885245901639344"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, clf1.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5TJjJ1y6EhD",
        "outputId": "157b2af9-a463-4b4d-d8ad-1eeb65f16973"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32, 25],\n",
              "       [13, 52]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 70.7% en el set de entrenamiento y del 68.85% para el de test"
      ],
      "metadata": {
        "id": "vzxHH9q56aEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASIFICADOR REDES NEURONALES**"
      ],
      "metadata": {
        "id": "hd24YQYcL4SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLPClassifier(hidden_layer_sizes=(8,8,8), max_iter=500, alpha=0.0001,\n",
        "                     solver='adam', random_state=21,tol=0.000000001)\n",
        "mlp.fit(X1_train,y_train)\n",
        "print(mlp.predict_proba([[63,145,233,150]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R264iXvHL82Z",
        "outputId": "9a7d109a-b2aa-42eb-93fb-e744bf32df4e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5638506 0.4361494]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el ejemplo se puede observar que tiene 43.61% de probabilidad que tenga un paro cardiaco y el 56.38% que no tenga paro cardiaco"
      ],
      "metadata": {
        "id": "h5Ihuw4pOLNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train, mlp.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwmp8yjVNHs5",
        "outputId": "d0ded24b-568d-4c57-b90f-31aaa0250435"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7237569060773481"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_train, mlp.predict(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaMUIMdINk5h",
        "outputId": "4c99430e-2190-41c3-ff53-d275ddd71996"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54, 27],\n",
              "       [23, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, mlp.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaT_L_ERNrMY",
        "outputId": "4e41d464-f92d-44d8-b4f0-0d1fbdff57a5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6557377049180327"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, mlp.predict(X1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3RXGIqVNyXI",
        "outputId": "afe22446-6070-4ac5-8e7c-0df36371ace2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29, 28],\n",
              "       [14, 51]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la mejor combinción de precisión que nos da es de 72.37% en el set de entrenamiento y del 65.57% para el de test"
      ],
      "metadata": {
        "id": "ctNTYaEbOcjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\\\n",
        "Lo que se puedo observar es que el clasificador vecino más cercano cuando k=8 tiene la mejor presición para el entrenamiento con un 78% y para el test la mejor presición es el clasificador bayesiano ingenuo con un 68.85%.\n"
      ],
      "metadata": {
        "id": "GhCmJrjkX1d1"
      }
    }
  ]
}